{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Example\n",
    "\n",
    "In this notebook we will show the most basic usage of **TGAN** in order to generate samples from a\n",
    "given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "The first step is to load the data wich we will use to fit TGAN. In order to do so, we will first\n",
    "import the function `tgan.data.load_data` and call it with the name the dataset that we want to load.\n",
    "\n",
    "In this case, we will load the `census` dataset, which we will use during the subsequent steps, and obtain two objects:\n",
    "\n",
    "1. `data` will contain a `pandas.DataFrame` with the table of data from the `census` dataset ready to be used to fit the model.\n",
    "\n",
    "2. `continous_columns` will contain a `list` with the indices of continuous columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tgan.model import TGANModel\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('../data/Ticket/Ticket_cat.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItinID</th>\n",
       "      <th>MktID</th>\n",
       "      <th>MktCoupons</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>OriginAirportID</th>\n",
       "      <th>OriginAirportSeqID</th>\n",
       "      <th>OriginCityMarketID</th>\n",
       "      <th>Origin</th>\n",
       "      <th>OriginCountry</th>\n",
       "      <th>...</th>\n",
       "      <th>OpCarrier</th>\n",
       "      <th>BulkFare</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>MktFare</th>\n",
       "      <th>MktDistance</th>\n",
       "      <th>MktDistanceGroup</th>\n",
       "      <th>MktMilesFlown</th>\n",
       "      <th>NonStopMiles</th>\n",
       "      <th>ItinGeoType</th>\n",
       "      <th>MktGeoType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201513772623</td>\n",
       "      <td>20151377262301</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>12892</td>\n",
       "      <td>1289203</td>\n",
       "      <td>32575</td>\n",
       "      <td>LAX</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>WN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201513772624</td>\n",
       "      <td>20151377262401</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>12892</td>\n",
       "      <td>1289203</td>\n",
       "      <td>32575</td>\n",
       "      <td>LAX</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>WN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201513772625</td>\n",
       "      <td>20151377262501</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>12892</td>\n",
       "      <td>1289203</td>\n",
       "      <td>32575</td>\n",
       "      <td>LAX</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>WN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201513772626</td>\n",
       "      <td>20151377262601</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>12892</td>\n",
       "      <td>1289203</td>\n",
       "      <td>32575</td>\n",
       "      <td>LAX</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>WN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201513772627</td>\n",
       "      <td>20151377262701</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>12892</td>\n",
       "      <td>1289203</td>\n",
       "      <td>32575</td>\n",
       "      <td>LAX</td>\n",
       "      <td>US</td>\n",
       "      <td>...</td>\n",
       "      <td>WN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ItinID           MktID  MktCoupons  Year  Quarter  OriginAirportID  \\\n",
       "0  201513772623  20151377262301           1  2015        1            12892   \n",
       "1  201513772624  20151377262401           1  2015        1            12892   \n",
       "2  201513772625  20151377262501           1  2015        1            12892   \n",
       "3  201513772626  20151377262601           1  2015        1            12892   \n",
       "4  201513772627  20151377262701           1  2015        1            12892   \n",
       "\n",
       "   OriginAirportSeqID  OriginCityMarketID Origin OriginCountry  ...  \\\n",
       "0             1289203               32575    LAX            US  ...   \n",
       "1             1289203               32575    LAX            US  ...   \n",
       "2             1289203               32575    LAX            US  ...   \n",
       "3             1289203               32575    LAX            US  ...   \n",
       "4             1289203               32575    LAX            US  ...   \n",
       "\n",
       "   OpCarrier BulkFare Passengers  MktFare  MktDistance  MktDistanceGroup  \\\n",
       "0         WN      0.0       12.0    120.0       1242.0                 3   \n",
       "1         WN      0.0        1.0    121.0       1242.0                 3   \n",
       "2         WN      0.0        1.0    126.0       1242.0                 3   \n",
       "3         WN      0.0       25.0    129.0       1242.0                 3   \n",
       "4         WN      0.0        3.0    131.0       1242.0                 3   \n",
       "\n",
       "   MktMilesFlown NonStopMiles ItinGeoType  MktGeoType  \n",
       "0         1242.0       1242.0           2           2  \n",
       "1         1242.0       1242.0           2           2  \n",
       "2         1242.0       1242.0           2           2  \n",
       "3         1242.0       1242.0           2           2  \n",
       "4         1242.0       1242.0           2           2  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 10, 13, 14, 15, 16, 19, 22, 25, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n"
     ]
    }
   ],
   "source": [
    "idxs = []\n",
    "for col in d._get_numeric_data().columns:\n",
    "    idxs.append(d.columns.get_loc(col))\n",
    "print(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ds, drop=None):\n",
    "    d = pd.read_csv(f'../data/{ds}/{ds}_cat.csv', sep=';')\n",
    "    if drop is not None:\n",
    "        d.drop(drop, axis=1)\n",
    "        \n",
    "    continuous_columns = []\n",
    "    for col in d._get_numeric_data().columns:\n",
    "        if len(d[col].unique()) > 20:\n",
    "            continuous_columns.append(d.columns.get_loc(col))\n",
    "    return d, continuous_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         ItinID           MktID  MktCoupons  Year  Quarter  OriginAirportID  \\\n",
       " 0  201513772623  20151377262301           1  2015        1            12892   \n",
       " 1  201513772624  20151377262401           1  2015        1            12892   \n",
       " 2  201513772625  20151377262501           1  2015        1            12892   \n",
       " 3  201513772626  20151377262601           1  2015        1            12892   \n",
       " 4  201513772627  20151377262701           1  2015        1            12892   \n",
       " \n",
       "    OriginAirportSeqID  OriginCityMarketID Origin OriginCountry  ...  \\\n",
       " 0             1289203               32575    LAX            US  ...   \n",
       " 1             1289203               32575    LAX            US  ...   \n",
       " 2             1289203               32575    LAX            US  ...   \n",
       " 3             1289203               32575    LAX            US  ...   \n",
       " 4             1289203               32575    LAX            US  ...   \n",
       " \n",
       "    OpCarrier BulkFare Passengers  MktFare  MktDistance  MktDistanceGroup  \\\n",
       " 0         WN      0.0       12.0    120.0       1242.0                 3   \n",
       " 1         WN      0.0        1.0    121.0       1242.0                 3   \n",
       " 2         WN      0.0        1.0    126.0       1242.0                 3   \n",
       " 3         WN      0.0       25.0    129.0       1242.0                 3   \n",
       " 4         WN      0.0        3.0    131.0       1242.0                 3   \n",
       " \n",
       "    MktMilesFlown NonStopMiles ItinGeoType  MktGeoType  \n",
       " 0         1242.0       1242.0           2           2  \n",
       " 1         1242.0       1242.0           2           2  \n",
       " 2         1242.0       1242.0           2           2  \n",
       " 3         1242.0       1242.0           2           2  \n",
       " 4         1242.0       1242.0           2           2  \n",
       " \n",
       " [5 rows x 41 columns],\n",
       " [0, 1, 5, 6, 7, 10, 13, 14, 15, 16, 19, 22, 33, 34, 35, 37, 38])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d, cont = get_data('Ticket')\n",
    "d.head(), cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bauke/anaconda3/envs/p3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('../data/berka/berka_cat.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.drop(['trans_bank_partner', 'trans_account_partner'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>trans_amount</th>\n",
       "      <th>balance_after_trans</th>\n",
       "      <th>trans_type</th>\n",
       "      <th>trans_operation</th>\n",
       "      <th>trans_k_symbol</th>\n",
       "      <th>trans_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>695247</td>\n",
       "      <td>2378</td>\n",
       "      <td>700.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>CREDIT_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171812</td>\n",
       "      <td>576</td>\n",
       "      <td>900.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>CREDIT_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207264</td>\n",
       "      <td>704</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>CREDIT_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1117247</td>\n",
       "      <td>3818</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>CREDIT_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>579373</td>\n",
       "      <td>1972</td>\n",
       "      <td>400.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>CREDIT_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trans_id  account_id  trans_amount  balance_after_trans trans_type  \\\n",
       "0    695247        2378         700.0                700.0     CREDIT   \n",
       "1    171812         576         900.0                900.0     CREDIT   \n",
       "2    207264         704        1000.0               1000.0     CREDIT   \n",
       "3   1117247        3818         600.0                600.0     CREDIT   \n",
       "4    579373        1972         400.0                400.0     CREDIT   \n",
       "\n",
       "  trans_operation trans_k_symbol  trans_date  \n",
       "0  CREDIT_IN_CASH        UNKNOWN           0  \n",
       "1  CREDIT_IN_CASH        UNKNOWN           0  \n",
       "2  CREDIT_IN_CASH        UNKNOWN           0  \n",
       "3  CREDIT_IN_CASH        UNKNOWN           0  \n",
       "4  CREDIT_IN_CASH        UNKNOWN           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_columns = [0, 1, 2, 3, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 7]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a TGAN instance\n",
    "\n",
    "The next step is to import TGAN and create an instance of the model.\n",
    "\n",
    "To do so, we need to import the `tgan.model.TGANModel` class and call it.\n",
    "\n",
    "This will create a TGAN instance with the default parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from comet_ml import Experiment\n",
    "# experiment = Experiment(api_key=\"49HGMPyIKjokHwg2pVOKWTG67\", project_name=\"gan-performance\", workspace=\"baukebrenninkmeijer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Comet.ml requires an API key. Please provide as the first argument to Experiment(api_key) or as an environment variable named COMET_API_KEY ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a774fe8cd8db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTGANModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinuous_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmax_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/TGAN_WGAN/tgan/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, continuous_columns, output, gpu, max_epoch, steps_per_epoch, save_checkpoints, restore_session, batch_size, z_dim, noise, l2norm, learning_rate, num_gen_rnn, num_gen_feature, num_dis_layers, num_dis_hidden, optimizer, comet_ml_key)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomet_ml_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomet_ml_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomet_ml_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tgan-wgan-gp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"baukebrenninkmeijer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/comet_ml/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, project_name, team_name, workspace, log_code, log_graph, auto_param_logging, auto_metric_logging, parse_args, auto_output_logging, log_env_details, log_git_metadata, log_git_patch, disabled, log_env_gpu, log_env_host)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             raise ValueError(\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;34m\"Comet.ml requires an API key. Please provide as the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m                 \u001b[0;34m\"first argument to Experiment(api_key) or as an environment\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;34m\" variable named COMET_API_KEY \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Comet.ml requires an API key. Please provide as the first argument to Experiment(api_key) or as an environment variable named COMET_API_KEY "
     ]
    }
   ],
   "source": [
    "tgan = TGANModel(continuous_columns, restore_session=False,  max_epoch=50, steps_per_epoch=1000, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit the model\n",
    "\n",
    "The third step is to pass the data that we have loaded previously to the `TGANModel.fit` method to\n",
    "start the fitting.\n",
    "\n",
    "This process will not return anything, however, the progress of the fitting will be printed into screen.\n",
    "\n",
    "**NOTE** Depending on the performance of the system you are running, and the parameters selected\n",
    "for the model, this step can take up to a few hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0522 08:30:37 @input_source.py:222]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
      "(<tf.Tensor 'QueueInput/input_deque:0' shape=(1000, 1) dtype=float32>, <tf.Tensor 'QueueInput/input_deque:1' shape=(1000, 5) dtype=float32>, <tf.Tensor 'QueueInput/input_deque:2' shape=(1000, 1) dtype=float32>, <tf.Tensor 'QueueInput/input_deque:3' shape=(1000, 5) dtype=float32>, <tf.Tensor 'QueueInput/input_deque:4' shape=(1000, 1) dtype=float32>, <tf.Tensor 'QueueInput/input_deque:5' shape=(1000, 5) dtype=float32>, <tf.Tensor 'QueueInput/input_deque:6' shape=(1000, 1) dtype=float32>, <tf.Tensor 'QueueInput/input_deque:7' shape=(1000, 5) dtype=float32>, <tf.Tensor 'QueueInput/input_deque:8' shape=(1000, 1) dtype=int32>, <tf.Tensor 'QueueInput/input_deque:9' shape=(1000, 1) dtype=int32>, <tf.Tensor 'QueueInput/input_deque:10' shape=(1000, 1) dtype=int32>, <tf.Tensor 'QueueInput/input_deque:11' shape=(1000, 1) dtype=float32>, <tf.Tensor 'QueueInput/input_deque:12' shape=(1000, 5) dtype=float32>)\n",
      "\u001b[32m[0522 08:30:43 @logger.py:125]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Log directory output/logs exists! Use 'd' to delete it. \n",
      "\u001b[32m[0522 08:30:43 @logger.py:128]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you're resuming from a previous run, you can choose to keep it.\n",
      "Press any other key to exit. \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select Action: k (keep) / d (delete) / q (quit): k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0522 08:32:14 @logger.py:83]\u001b[0m Existing log file 'output/logs/log.log' backuped to 'output/logs/log.log.0522-083214'\n",
      "\u001b[32m[0522 08:32:14 @logger.py:90]\u001b[0m Argv: /home/bauke/anaconda3/envs/p3.6/lib/python3.6/site-packages/ipykernel_launcher.py -f /run/user/1000/jupyter/kernel-5db58c25-eae8-49ea-97e0-1e3ec0fac56c.json\n",
      "\u001b[32m[0522 08:32:14 @model_utils.py:67]\u001b[0m \u001b[36mList of Trainable Variables: \n",
      "\u001b[0mname                              shape           #elements\n",
      "--------------------------------  ------------  -----------\n",
      "gen/LSTM/go:0                     [1, 100]              100\n",
      "gen/LSTM/lstm_cell/kernel:0       [500, 400]         200000\n",
      "gen/LSTM/lstm_cell/bias:0         [400]                 400\n",
      "gen/LSTM/00/FC/W:0                [100, 100]          10000\n",
      "gen/LSTM/00/FC/b:0                [100]                 100\n",
      "gen/LSTM/00/FC2/W:0               [100, 1]              100\n",
      "gen/LSTM/00/FC2/b:0               [1]                     1\n",
      "gen/LSTM/00/attw:0                [1, 1, 1]               1\n",
      "gen/LSTM/01/FC/W:0                [100, 100]          10000\n",
      "gen/LSTM/01/FC/b:0                [100]                 100\n",
      "gen/LSTM/01/FC2/W:0               [100, 5]              500\n",
      "gen/LSTM/01/FC2/b:0               [5]                     5\n",
      "gen/LSTM/01/FC3/W:0               [5, 100]              500\n",
      "gen/LSTM/01/FC3/b:0               [100]                 100\n",
      "gen/LSTM/01/attw:0                [2, 1, 1]               2\n",
      "gen/LSTM/02/FC/W:0                [100, 100]          10000\n",
      "gen/LSTM/02/FC/b:0                [100]                 100\n",
      "gen/LSTM/02/FC2/W:0               [100, 1]              100\n",
      "gen/LSTM/02/FC2/b:0               [1]                     1\n",
      "gen/LSTM/02/attw:0                [3, 1, 1]               3\n",
      "gen/LSTM/03/FC/W:0                [100, 100]          10000\n",
      "gen/LSTM/03/FC/b:0                [100]                 100\n",
      "gen/LSTM/03/FC2/W:0               [100, 5]              500\n",
      "gen/LSTM/03/FC2/b:0               [5]                     5\n",
      "gen/LSTM/03/FC3/W:0               [5, 100]              500\n",
      "gen/LSTM/03/FC3/b:0               [100]                 100\n",
      "gen/LSTM/03/attw:0                [4, 1, 1]               4\n",
      "gen/LSTM/04/FC/W:0                [100, 100]          10000\n",
      "gen/LSTM/04/FC/b:0                [100]                 100\n",
      "gen/LSTM/04/FC2/W:0               [100, 1]              100\n",
      "gen/LSTM/04/FC2/b:0               [1]                     1\n",
      "gen/LSTM/04/attw:0                [5, 1, 1]               5\n",
      "gen/LSTM/05/FC/W:0                [100, 100]          10000\n",
      "gen/LSTM/05/FC/b:0                [100]                 100\n",
      "gen/LSTM/05/FC2/W:0               [100, 5]              500\n",
      "gen/LSTM/05/FC2/b:0               [5]                     5\n",
      "gen/LSTM/05/FC3/W:0               [5, 100]              500\n",
      "gen/LSTM/05/FC3/b:0               [100]                 100\n",
      "gen/LSTM/05/attw:0                [6, 1, 1]               6\n",
      "gen/LSTM/06/FC/W:0                [100, 100]          10000\n",
      "gen/LSTM/06/FC/b:0                [100]                 100\n",
      "gen/LSTM/06/FC2/W:0               [100, 1]              100\n",
      "gen/LSTM/06/FC2/b:0               [1]                     1\n",
      "gen/LSTM/06/attw:0                [7, 1, 1]               7\n",
      "gen/LSTM/07/FC/W:0                [100, 100]          10000\n",
      "gen/LSTM/07/FC/b:0                [100]                 100\n",
      "gen/LSTM/07/FC2/W:0               [100, 5]              500\n",
      "gen/LSTM/07/FC2/b:0               [5]                     5\n",
      "gen/LSTM/07/FC3/W:0               [5, 100]              500\n",
      "gen/LSTM/07/FC3/b:0               [100]                 100\n",
      "gen/LSTM/07/attw:0                [8, 1, 1]               8\n",
      "gen/LSTM/08/FC/W:0                [100, 100]          10000\n",
      "gen/LSTM/08/FC/b:0                [100]                 100\n",
      "gen/LSTM/08/FC2/W:0               [100, 3]              300\n",
      "gen/LSTM/08/FC2/b:0               [3]                     3\n",
      "gen/LSTM/08/FC3/W:0               [3, 100]              300\n",
      "gen/LSTM/08/FC3/b:0               [100]                 100\n",
      "gen/LSTM/08/attw:0                [9, 1, 1]               9\n",
      "gen/LSTM/09/FC/W:0                [100, 100]          10000\n",
      "gen/LSTM/09/FC/b:0                [100]                 100\n",
      "gen/LSTM/09/FC2/W:0               [100, 6]              600\n",
      "gen/LSTM/09/FC2/b:0               [6]                     6\n",
      "gen/LSTM/09/FC3/W:0               [6, 100]              600\n",
      "gen/LSTM/09/FC3/b:0               [100]                 100\n",
      "gen/LSTM/09/attw:0                [10, 1, 1]             10\n",
      "gen/LSTM/10/FC/W:0                [100, 100]          10000\n",
      "gen/LSTM/10/FC/b:0                [100]                 100\n",
      "gen/LSTM/10/FC2/W:0               [100, 8]              800\n",
      "gen/LSTM/10/FC2/b:0               [8]                     8\n",
      "gen/LSTM/10/FC3/W:0               [8, 100]              800\n",
      "gen/LSTM/10/FC3/b:0               [100]                 100\n",
      "gen/LSTM/10/attw:0                [11, 1, 1]             11\n",
      "gen/LSTM/11/FC/W:0                [100, 100]          10000\n",
      "gen/LSTM/11/FC/b:0                [100]                 100\n",
      "gen/LSTM/11/FC2/W:0               [100, 1]              100\n",
      "gen/LSTM/11/FC2/b:0               [1]                     1\n",
      "gen/LSTM/11/attw:0                [12, 1, 1]             12\n",
      "gen/LSTM/12/FC/W:0                [100, 100]          10000\n",
      "gen/LSTM/12/FC/b:0                [100]                 100\n",
      "gen/LSTM/12/FC2/W:0               [100, 5]              500\n",
      "gen/LSTM/12/FC2/b:0               [5]                     5\n",
      "gen/LSTM/12/FC3/W:0               [5, 100]              500\n",
      "gen/LSTM/12/FC3/b:0               [100]                 100\n",
      "gen/LSTM/12/attw:0                [13, 1, 1]             13\n",
      "discrim/dis_fc0/fc/W:0            [47, 100]            4700\n",
      "discrim/dis_fc0/fc/b:0            [100]                 100\n",
      "discrim/dis_fc0/fc_diversity/W:0  [100, 100]          10000\n",
      "discrim/dis_fc0/fc_diversity/b:0  [100]                 100\n",
      "discrim/dis_fc0/bn/beta:0         [110]                 110\n",
      "discrim/dis_fc_top/W:0            [110, 1]              110\n",
      "discrim/dis_fc_top/b:0            [1]                     1\n",
      "dis_fc0/fc/W:0                    [47000, 100]      4700000\n",
      "dis_fc0/fc/b:0                    [100]                 100\n",
      "dis_fc0/fc_diversity/W:0          [100, 100]          10000\n",
      "dis_fc0/fc_diversity/b:0          [100]                 100\n",
      "dis_fc0/bn/beta:0                 [110]                 110\n",
      "dis_fc_top/W:0                    [110, 1]              110\n",
      "dis_fc_top/b:0                    [1]                     1\u001b[36m\n",
      "Number of trainable variables: 98\n",
      "Number of parameters (elements): 5067180\n",
      "Storage space needed for all trainable variables: 19.33MB\u001b[0m\n",
      "\u001b[32m[0522 08:32:14 @base.py:209]\u001b[0m Setup callbacks graph ...\n",
      "\u001b[32m[0522 08:32:15 @summary.py:46]\u001b[0m [MovingAverageSummary] 3 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n",
      "\u001b[32m[0522 08:32:15 @summary.py:93]\u001b[0m Summarizing collection 'summaries' of size 8.\n",
      "\u001b[32m[0522 08:32:15 @graph.py:98]\u001b[0m Applying collection UPDATE_OPS of 6 ops.\n",
      "\u001b[32m[0522 08:32:16 @base.py:230]\u001b[0m Creating the session ...\n",
      "\u001b[32m[0522 08:32:17 @base.py:236]\u001b[0m Initializing the session ...\n",
      "\u001b[32m[0522 08:32:17 @base.py:243]\u001b[0m Graph Finalized.\n",
      "\u001b[32m[0522 08:32:17 @concurrency.py:38]\u001b[0m Starting EnqueueThread QueueInput/input_queue ...\n",
      "\u001b[32m[0522 08:32:18 @monitor.py:352]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m History epoch=25 from JSON is not the predecessor of the current starting_epoch=1\n",
      "\u001b[32m[0522 08:32:18 @monitor.py:353]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m If you want to resume old training, either use `AutoResumeTrainConfig` or correctly set the new starting_epoch yourself to avoid inconsistency. \n",
      "\u001b[32m[0522 08:32:18 @monitor.py:360]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Now, we will train with starting_epoch=1 and backup old json to output/logs/stats.json.0522-083218\n",
      "\u001b[32m[0522 08:32:18 @base.py:275]\u001b[0m Start Epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|1000/1000[04:24<00:00, 1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0522 08:36:42 @base.py:285]\u001b[0m Epoch 1 (global_step 1000) finished, time:4 minutes 24 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0522 08:36:43 @saver.py:79]\u001b[0m Model saved to output/model/model-1000.\n",
      "\u001b[32m[0522 08:36:43 @monitor.py:467]\u001b[0m GAN_loss/discrim/GP: 58398\n",
      "\u001b[32m[0522 08:36:43 @monitor.py:467]\u001b[0m GAN_loss/discrim/d_loss: 5.8398e+05\n",
      "\u001b[32m[0522 08:36:43 @monitor.py:467]\u001b[0m GAN_loss/gen/g_loss: -1.0174\n",
      "\u001b[32m[0522 08:36:43 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0522 08:36:43 @base.py:275]\u001b[0m Start Epoch 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########|1000/1000[04:19<00:00, 3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0522 08:41:03 @base.py:285]\u001b[0m Epoch 2 (global_step 2000) finished, time:4 minutes 19 seconds.\n",
      "\u001b[32m[0522 08:41:03 @saver.py:79]\u001b[0m Model saved to output/model/model-2000.\n",
      "\u001b[32m[0522 08:41:03 @monitor.py:467]\u001b[0m GAN_loss/discrim/GP: 69424\n",
      "\u001b[32m[0522 08:41:03 @monitor.py:467]\u001b[0m GAN_loss/discrim/d_loss: 6.9423e+05\n",
      "\u001b[32m[0522 08:41:03 @monitor.py:467]\u001b[0m GAN_loss/gen/g_loss: 3.7221\n",
      "\u001b[32m[0522 08:41:03 @monitor.py:467]\u001b[0m QueueInput/queue_size: 50\n",
      "\u001b[32m[0522 08:41:03 @base.py:275]\u001b[0m Start Epoch 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|#####8    |587/1000[02:32<01:47, 3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0522 08:43:36 @base.py:293]\u001b[0m Detected Ctrl-C and exiting main loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-eaad281d90c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'demo/my_model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TGAN_WGAN/tgan/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mmax_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0msession_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mstarting_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarting_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m         )\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorpack/train/base.py\u001b[0m in \u001b[0;36mtrain_with_defaults\u001b[0;34m(self, _sentinel, callbacks, monitors, session_creator, session_init, steps_per_epoch, starting_epoch, max_epoch, extra_callbacks)\u001b[0m\n\u001b[1;32m    342\u001b[0m         self.train(callbacks, monitors,\n\u001b[1;32m    343\u001b[0m                    \u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                    steps_per_epoch, starting_epoch, max_epoch)\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorpack/train/base.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, callbacks, monitors, session_creator, session_init, steps_per_epoch, starting_epoch, max_epoch)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarting_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     def train_with_defaults(\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorpack/utils/argtools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorpack/train/base.py\u001b[0m in \u001b[0;36mmain_loop\u001b[0;34m(self, steps_per_epoch, starting_epoch, max_epoch)\u001b[0m\n\u001b[1;32m    279\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooked_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# implemented by subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorpack/train/base.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;34m\"Please either set `Trainer.train_op` or provide an implementation \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \"of Trainer.run_step()!\")\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooked_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcall_only_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    669\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1157\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tgan.fit(d)\n",
    "model_path = 'demo/my_model'\n",
    "\n",
    "tgan.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sample new data\n",
    "\n",
    "After the model has been fit, we are ready to generate new samples by calling the `TGANModel.sample`\n",
    "method passing it the desired amount of samples.\n",
    "\n",
    "The returned object, `samples`, is a `pandas.DataFrame` containing a table of synthetic data with\n",
    "the same format as the input data and 1000 rows as we requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "?|399/?[00:03<00:00,106.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>trans_amount</th>\n",
       "      <th>balance_after_trans</th>\n",
       "      <th>trans_type</th>\n",
       "      <th>trans_operation</th>\n",
       "      <th>trans_k_symbol</th>\n",
       "      <th>trans_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.313015e+05</td>\n",
       "      <td>2412.346404</td>\n",
       "      <td>-697.238617</td>\n",
       "      <td>62372.132949</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>WITHDRAWAL_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1226.659261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.807175e+05</td>\n",
       "      <td>537.811549</td>\n",
       "      <td>25009.036967</td>\n",
       "      <td>62272.442144</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>CREDIT_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2011.850061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.993796e+05</td>\n",
       "      <td>1384.407952</td>\n",
       "      <td>-666.895970</td>\n",
       "      <td>22699.081086</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>REMITTANCE_TO_OTHER_BANK</td>\n",
       "      <td>INSURANCE_PAYMENT</td>\n",
       "      <td>1937.274590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.533511e+05</td>\n",
       "      <td>417.378888</td>\n",
       "      <td>775.283616</td>\n",
       "      <td>53160.347749</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>REMITTANCE_TO_OTHER_BANK</td>\n",
       "      <td>INSURANCE_PAYMENT</td>\n",
       "      <td>1095.971931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.957608e+05</td>\n",
       "      <td>461.486269</td>\n",
       "      <td>-52.909450</td>\n",
       "      <td>38055.185932</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>WITHDRAWAL_IN_CASH</td>\n",
       "      <td>PAYMENT_FOR_STATEMENT</td>\n",
       "      <td>1920.859350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.602992e+06</td>\n",
       "      <td>986.257363</td>\n",
       "      <td>7.028790</td>\n",
       "      <td>9005.636065</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>INTEREST_CREDITED</td>\n",
       "      <td>2171.315480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.126110e+06</td>\n",
       "      <td>3481.758244</td>\n",
       "      <td>-1021.417024</td>\n",
       "      <td>43876.876451</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>REMITTANCE_TO_OTHER_BANK</td>\n",
       "      <td>INSURANCE_PAYMENT</td>\n",
       "      <td>1878.332241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.632089e+06</td>\n",
       "      <td>2301.954204</td>\n",
       "      <td>2.555189</td>\n",
       "      <td>7973.871042</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>INTEREST_CREDITED</td>\n",
       "      <td>1992.822675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.657328e+06</td>\n",
       "      <td>1695.505997</td>\n",
       "      <td>152.640724</td>\n",
       "      <td>25883.250439</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>INTEREST_CREDITED</td>\n",
       "      <td>1754.966151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.223307e+05</td>\n",
       "      <td>1129.850558</td>\n",
       "      <td>726.509534</td>\n",
       "      <td>7518.877092</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>COLLECTION_FROM_OTHER_BANK</td>\n",
       "      <td>OLD_AGE_PENSION</td>\n",
       "      <td>1939.918932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.002800e+06</td>\n",
       "      <td>8036.393357</td>\n",
       "      <td>2438.261357</td>\n",
       "      <td>20737.836288</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>WITHDRAWAL_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1183.844038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.365320e+06</td>\n",
       "      <td>7793.595764</td>\n",
       "      <td>3718.882421</td>\n",
       "      <td>51551.204684</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>WITHDRAWAL_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>551.031424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.629463e+06</td>\n",
       "      <td>49.144422</td>\n",
       "      <td>198.536488</td>\n",
       "      <td>53332.705213</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>INTEREST_CREDITED</td>\n",
       "      <td>2029.107198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.609159e+06</td>\n",
       "      <td>950.676572</td>\n",
       "      <td>130.167516</td>\n",
       "      <td>51024.578967</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>INTEREST_CREDITED</td>\n",
       "      <td>1918.388875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.156157e+06</td>\n",
       "      <td>3381.489941</td>\n",
       "      <td>965.660854</td>\n",
       "      <td>10821.638475</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>WITHDRAWAL_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1560.785971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.588636e+06</td>\n",
       "      <td>184.986698</td>\n",
       "      <td>-950.516073</td>\n",
       "      <td>56973.436410</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>INTEREST_CREDITED</td>\n",
       "      <td>2055.321486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.731484e+05</td>\n",
       "      <td>199.482633</td>\n",
       "      <td>-494.383604</td>\n",
       "      <td>11044.043456</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>WITHDRAWAL_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1191.934053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.054605e+05</td>\n",
       "      <td>-24.805726</td>\n",
       "      <td>25328.015059</td>\n",
       "      <td>63531.986478</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>WITHDRAWAL_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1500.905687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.529813e+06</td>\n",
       "      <td>10345.472459</td>\n",
       "      <td>6474.278127</td>\n",
       "      <td>30563.033346</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>WITHDRAWAL_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>469.731872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.842761e+05</td>\n",
       "      <td>560.279832</td>\n",
       "      <td>2114.150455</td>\n",
       "      <td>51426.978123</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>WITHDRAWAL_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1119.017941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        trans_id    account_id  trans_amount  balance_after_trans  trans_type  \\\n",
       "0   8.313015e+05   2412.346404   -697.238617         62372.132949  WITHDRAWAL   \n",
       "1   2.807175e+05    537.811549  25009.036967         62272.442144      CREDIT   \n",
       "2   4.993796e+05   1384.407952   -666.895970         22699.081086  WITHDRAWAL   \n",
       "3   2.533511e+05    417.378888    775.283616         53160.347749  WITHDRAWAL   \n",
       "4   1.957608e+05    461.486269    -52.909450         38055.185932  WITHDRAWAL   \n",
       "5   3.602992e+06    986.257363      7.028790          9005.636065      CREDIT   \n",
       "6   1.126110e+06   3481.758244  -1021.417024         43876.876451  WITHDRAWAL   \n",
       "7   3.632089e+06   2301.954204      2.555189          7973.871042      CREDIT   \n",
       "8   3.657328e+06   1695.505997    152.640724         25883.250439      CREDIT   \n",
       "9   4.223307e+05   1129.850558    726.509534          7518.877092      CREDIT   \n",
       "10  3.002800e+06   8036.393357   2438.261357         20737.836288  WITHDRAWAL   \n",
       "11  1.365320e+06   7793.595764   3718.882421         51551.204684  WITHDRAWAL   \n",
       "12  3.629463e+06     49.144422    198.536488         53332.705213      CREDIT   \n",
       "13  3.609159e+06    950.676572    130.167516         51024.578967      CREDIT   \n",
       "14  1.156157e+06   3381.489941    965.660854         10821.638475  WITHDRAWAL   \n",
       "15  3.588636e+06    184.986698   -950.516073         56973.436410      CREDIT   \n",
       "16  1.731484e+05    199.482633   -494.383604         11044.043456  WITHDRAWAL   \n",
       "17  1.054605e+05    -24.805726  25328.015059         63531.986478  WITHDRAWAL   \n",
       "18  3.529813e+06  10345.472459   6474.278127         30563.033346     UNKNOWN   \n",
       "19  2.842761e+05    560.279832   2114.150455         51426.978123  WITHDRAWAL   \n",
       "\n",
       "               trans_operation         trans_k_symbol   trans_date  \n",
       "0           WITHDRAWAL_IN_CASH                UNKNOWN  1226.659261  \n",
       "1               CREDIT_IN_CASH                UNKNOWN  2011.850061  \n",
       "2     REMITTANCE_TO_OTHER_BANK      INSURANCE_PAYMENT  1937.274590  \n",
       "3     REMITTANCE_TO_OTHER_BANK      INSURANCE_PAYMENT  1095.971931  \n",
       "4           WITHDRAWAL_IN_CASH  PAYMENT_FOR_STATEMENT  1920.859350  \n",
       "5                      UNKNOWN      INTEREST_CREDITED  2171.315480  \n",
       "6     REMITTANCE_TO_OTHER_BANK      INSURANCE_PAYMENT  1878.332241  \n",
       "7                      UNKNOWN      INTEREST_CREDITED  1992.822675  \n",
       "8                      UNKNOWN      INTEREST_CREDITED  1754.966151  \n",
       "9   COLLECTION_FROM_OTHER_BANK        OLD_AGE_PENSION  1939.918932  \n",
       "10          WITHDRAWAL_IN_CASH                UNKNOWN  1183.844038  \n",
       "11          WITHDRAWAL_IN_CASH                UNKNOWN   551.031424  \n",
       "12                     UNKNOWN      INTEREST_CREDITED  2029.107198  \n",
       "13                     UNKNOWN      INTEREST_CREDITED  1918.388875  \n",
       "14          WITHDRAWAL_IN_CASH                UNKNOWN  1560.785971  \n",
       "15                     UNKNOWN      INTEREST_CREDITED  2055.321486  \n",
       "16          WITHDRAWAL_IN_CASH                UNKNOWN  1191.934053  \n",
       "17          WITHDRAWAL_IN_CASH                UNKNOWN  1500.905687  \n",
       "18          WITHDRAWAL_IN_CASH                UNKNOWN   469.731872  \n",
       "19          WITHDRAWAL_IN_CASH                UNKNOWN  1119.017941  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 100000\n",
    "\n",
    "samples = tgan.sample(num_samples)\n",
    "\n",
    "samples.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = samples.copy()\n",
    "p[['trans_id', 'account_id', 'trans_amount', 'balance_after_trans', 'trans_date']] = p[['trans_id', 'account_id', 'trans_amount', 'balance_after_trans', 'trans_date']].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.to_csv('samples/berka_sample_wgan.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save and Load a model\n",
    "\n",
    "In the steps above we saw that the fitting process is slow, so we probably would like to avoid having to fit every we want to generate samples. Instead we can fit a model once, save it, and load it every time we want to sample new data.\n",
    "\n",
    "If we have a fitted model, we can save it by calling the `TGANModel.save` method, that only takes\n",
    "as argument the path to store the model into. Similarly, the `TGANModel.load` allows to load a model stored on disk by passing as argument a path where the model is stored.\n",
    "\n",
    "At this point we could use this model instance to generate more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0520 11:02:32 @model.py:813]\u001b[0m Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "model_path = 'model/berka_wgan_100x1000'\n",
    "\n",
    "tgan.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'input00value:0' shape=(1000, 1) dtype=float32>, <tf.Tensor 'input00cluster:0' shape=(1000, 5) dtype=float32>, <tf.Tensor 'input01value:0' shape=(1000, 1) dtype=float32>, <tf.Tensor 'input01cluster:0' shape=(1000, 5) dtype=float32>, <tf.Tensor 'input02value:0' shape=(1000, 1) dtype=float32>, <tf.Tensor 'input02cluster:0' shape=(1000, 5) dtype=float32>, <tf.Tensor 'input03value:0' shape=(1000, 1) dtype=float32>, <tf.Tensor 'input03cluster:0' shape=(1000, 5) dtype=float32>, <tf.Tensor 'input04:0' shape=(1000, 1) dtype=int32>, <tf.Tensor 'input05:0' shape=(1000, 1) dtype=int32>, <tf.Tensor 'input06:0' shape=(1000, 1) dtype=int32>, <tf.Tensor 'input07value:0' shape=(1000, 1) dtype=float32>, <tf.Tensor 'input07cluster:0' shape=(1000, 5) dtype=float32>)\n",
      "\u001b[32m[0524 12:20:10 @collection.py:165]\u001b[0m These collections were modified but restored in : (tf.GraphKeys.SUMMARIES: 0->7)\n",
      "\u001b[32m[0524 12:20:10 @sessinit.py:87]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the checkpoint, but not found in the graph: global_step, optimize/beta1_power, optimize/beta2_power\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\u001b[32m[0524 12:20:11 @sessinit.py:114]\u001b[0m Restoring checkpoint from output/model/model-100000 ...\n",
      "INFO:tensorflow:Restoring parameters from output/model/model-100000\n"
     ]
    }
   ],
   "source": [
    "model_path = 'model/berka_wgan_100x1000'\n",
    "new_tgan = TGANModel.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|9         |99/1000[00:02<00:24,36.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>trans_amount</th>\n",
       "      <th>balance_after_trans</th>\n",
       "      <th>trans_type</th>\n",
       "      <th>trans_operation</th>\n",
       "      <th>trans_k_symbol</th>\n",
       "      <th>trans_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>624133.772715</td>\n",
       "      <td>2091.647880</td>\n",
       "      <td>7601.496306</td>\n",
       "      <td>11070.709384</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>WITHDRAWAL_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1760.831643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171180.893366</td>\n",
       "      <td>574.151060</td>\n",
       "      <td>12276.828773</td>\n",
       "      <td>61765.710178</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>WITHDRAWAL_IN_CASH</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2076.040168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>511430.606576</td>\n",
       "      <td>1715.231147</td>\n",
       "      <td>8919.582528</td>\n",
       "      <td>52761.409552</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "      <td>REMITTANCE_TO_OTHER_BANK</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>993.931269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        trans_id   account_id  trans_amount  balance_after_trans  trans_type  \\\n",
       "0  624133.772715  2091.647880   7601.496306         11070.709384  WITHDRAWAL   \n",
       "1  171180.893366   574.151060  12276.828773         61765.710178  WITHDRAWAL   \n",
       "2  511430.606576  1715.231147   8919.582528         52761.409552  WITHDRAWAL   \n",
       "\n",
       "            trans_operation trans_k_symbol   trans_date  \n",
       "0        WITHDRAWAL_IN_CASH        UNKNOWN  1760.831643  \n",
       "1        WITHDRAWAL_IN_CASH        UNKNOWN  2076.040168  \n",
       "2  REMITTANCE_TO_OTHER_BANK      HOUSEHOLD   993.931269  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 100000\n",
    "new_samples = new_tgan.sample(num_samples)\n",
    "\n",
    "new_samples.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = new_samples.copy()\n",
    "p[p._get_numeric_data().columns] = p[p._get_numeric_data().columns].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.to_csv('samples/berka_sample_wgan_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading custom datasets\n",
    "\n",
    "In the previous steps we used some demonstration data but we did not show how to load your own dataset.\n",
    "\n",
    "In order to do so you can use `pandas.read_csv` by passing it the path to the CSV file that you want to load.\n",
    "\n",
    "Additionally, you will need to create 0-indexed list of columns indices to be considered continuous.\n",
    "\n",
    "For example, if we want to load a local CSV file, `path/to/my.csv`, that has as continuous columns their first 4 columns, that is, indices `[0,1,2,3]`, we would do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/census.csv')\n",
    "\n",
    "continuous_columns = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters\n",
    "\n",
    "If you want to change the default behavior of TGANModel, such as as different `batch_size` or\n",
    "`num_epochs`, you can do so by passing different arguments when creating the instance. Have b\n",
    "\n",
    "### Model general behavior\n",
    "\n",
    "* continous_columns (`list[int]`, required): List of columns to be considered continuous.\n",
    "* output (`str`, default=`output`): Path to store the model and its artifacts.\n",
    "* gpu (`list[str]`, default=`[]`): Comma separated list of GPU(s) to use.\n",
    "\n",
    "### Neural network definition and fitting\n",
    "\n",
    "* max_epoch (`int`, default=`100`): Number of epochs to use during training.\n",
    "* steps_per_epoch (`int`, default=`10000`): Number of steps to run on each epoch.\n",
    "* save_checkpoints(`bool`, default=True): Whether or not to store checkpoints of the model after each training epoch.\n",
    "* restore_session(`bool`, default=True): Whether or not continue training from the last checkpoint.\n",
    "* batch_size (`int`, default=`200`): Size of the batch to feed the model at each step.\n",
    "* z_dim (`int`, default=`100`): Number of dimensions in the noise input for the generator.\n",
    "* noise (`float`, default=`0.2`): Upper bound to the gaussian noise added to categorical columns.\n",
    "* l2norm (`float`, default=`0.00001`): L2 reguralization coefficient when computing losses.\n",
    "* learning_rate (`float`, default=`0.001`): Learning rate for the optimizer.\n",
    "* num_gen_rnn (`int`, default=`400`):\n",
    "* num_gen_feature (`int`, default=`100`): Number of features of in the generator.\n",
    "* num_dis_layers (`int`, default=`2`):\n",
    "* num_dis_hidden (`int`, default=`200`):\n",
    "* optimizer (`str`, default=`AdamOptimizer`): Name of the optimizer to use during `fit`, possible\n",
    "  values are: [`GradientDescentOptimizer`, `AdamOptimizer`, `AdadeltaOptimizer`].\n",
    "\n",
    "If we wanted to create an identical instance to the one created on step 2, but passing the arguments in a explicit way we will do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgan = TGANModel(\n",
    "    continuous_columns,\n",
    "    output='output',\n",
    "    gpu=None,\n",
    "    max_epoch=5,\n",
    "    steps_per_epoch=10000,\n",
    "    save_checkpoints=True,\n",
    "    restore_session=True,\n",
    "    batch_size=200,\n",
    "    z_dim=200,\n",
    "    noise=0.2,\n",
    "    l2norm=0.00001,\n",
    "    learning_rate=0.001,\n",
    "    num_gen_rnn=100,\n",
    "    num_gen_feature=100,\n",
    "    num_dis_layers=1,\n",
    "    num_dis_hidden=100,\n",
    "    optimizer='AdamOptimizer'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command-line interface\n",
    "\n",
    "We include a command-line interface that allows users to access TGAN functionality. Currently only one action is supported.\n",
    "\n",
    "### Random hyperparameter search\n",
    "\n",
    "#### Input\n",
    "\n",
    "To run random searchs for the best model hyperparameters for a given dataset, we will need:\n",
    "\n",
    "* A dataset, in a csv file, without any missing value, only columns of type `bool`, `str`, `int` or\n",
    "  `float` and only one type for column, as specified in [Data Format Input](#data-format-input).\n",
    "\n",
    "* A JSON file containing the configuration for the search. This configuration shall contain:\n",
    "\n",
    "  * `name`: Name of the experiment. A folder with this name will be created.\n",
    "  * `num_random_search`: Number of iterations in hyper parameter search.\n",
    "  * `train_csv`: Path to the csv file containing the dataset.\n",
    "  * `continuous_cols`: List of column indices, starting at 0, to be considered continuous.\n",
    "  * `epoch`: Number of epoches to train the model.\n",
    "  * `steps_per_epoch`: Number of optimization steps in each epoch.\n",
    "  * `sample_rows`: Number of rows to sample when evaluating the model.\n",
    "\n",
    "You can see an example of such a json file in [examples/config.json](examples/config.json), which you\n",
    "can download and use as a template.\n",
    "\n",
    "#### Execution\n",
    "\n",
    "Once we have prepared everything we can launch the random hyperparameter search with this command:\n",
    "\n",
    "``` bash\n",
    "tgan experiments config.json results.json\n",
    "```\n",
    "\n",
    "Where the first argument, `config.json`,  is the path to your configuration JSON, and the second,\n",
    "`results.json`, is the path to store the summary of the execution.\n",
    "\n",
    "This will run the random search, wich basically consist of the folling steps:\n",
    "\n",
    "1. We fetch and split our data between test and train.\n",
    "2. We randomly select the hyperparameters to test.\n",
    "3. Then, for each hyperparameter combination, we train a TGAN model using the real training data T\n",
    "   and generate a synthetic training dataset Tsynth.\n",
    "4. We then train machine learning models on both the real and synthetic datasets.\n",
    "5. We use these trained models on real test data and see how well they perform.\n",
    "\n",
    "#### Output\n",
    "\n",
    "One the experiment has finished, the following can be found:\n",
    "\n",
    "* A JSON file, in the example above called `results.json`, containing a summary of the experiments.\n",
    "  This JSON will contain a key for each experiment `name`, and on it, an array of length\n",
    "  `num_random_search`, with the selected parameters and its evaluation score. For a configuration\n",
    "  like the example, the summary will look like this:\n",
    "\n",
    "``` python\n",
    "{\n",
    "    'census': [\n",
    "        {\n",
    "            \"steps_per_epoch\" : 10000,\n",
    "            \"num_gen_feature\" : 300,\n",
    "            \"num_dis_hidden\" : 300,\n",
    "            \"batch_size\" : 100,\n",
    "            \"num_gen_rnn\" : 400,\n",
    "            \"score\" : 0.937802280415988,\n",
    "            \"max_epoch\" : 5,\n",
    "            \"num_dis_layers\" : 4,\n",
    "            \"learning_rate\" : 0.0002,\n",
    "            \"z_dim\" : 100,\n",
    "            \"noise\" : 0.2\n",
    "        },\n",
    "        ... # 9 more nodes\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "* A set of folders, each one names after the `name` specified in the JSON configuration, contained\n",
    "in the `experiments` folder. In each folder, sampled data and the models can be found. For a configuration\n",
    "like the example, this will look like this:\n",
    "\n",
    "```\n",
    "experiments/\n",
    "  census/\n",
    "    data/       # Sampled data with each of the models in the random search.\n",
    "    model_0/\n",
    "      logs/     # Training logs\n",
    "      model/    # Tensorflow model checkpoints\n",
    "    model_1/    # 9 more folders, one for each model in the random search\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation\n",
    "\n",
    "If you use TGAN, please cite the following work:\n",
    "\n",
    "> Lei Xu, Kalyan Veeramachaneni. 2018. Synthesizing Tabular Data using Generative Adversarial Networks.\n",
    "\n",
    "```LaTeX\n",
    "@article{xu2018synthesizing,\n",
    "  title={Synthesizing Tabular Data using Generative Adversarial Networks},\n",
    "  author={Xu, Lei and Veeramachaneni, Kalyan},\n",
    "  journal={arXiv preprint arXiv:1811.11264},\n",
    "  year={2018}\n",
    "}\n",
    "```\n",
    "You can find the original paper [here](https://arxiv.org/pdf/1811.11264.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6",
   "language": "python",
   "name": "p3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
